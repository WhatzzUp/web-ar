<!DOCTYPE html>
<html lang="en">

<head>
    <title>XR Spinosaurus</title>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- import the webpage's stylesheet -->
    <link rel="stylesheet" href="/style.css">
    <style>
        div#text {
            position: absolute;
            left: 6px;
            top: 6px;
            padding: 6px;
            /*
      text-shadow: 0 0 5px white;
      */
            max-width: 350px;
            background-color: rgba(255, 255, 255, 0.7)
        }
    </style>
    <script>
        // WebXR requires HTTPS, so the site doesn't work if someone manually enters
        // the URL and ends up using HTTP. To work around this, force redirect from
        // http to https for non-localhost addresses.
        if (window.location.protocol == "http:" &&
            window.location.hostname != "localhost" &&
            window.location.hostname != "127.0.0.1" &&
            window.location.hostname != "[::1]") {
            window.location = window.location.href.replace('http:', 'https:');
        }
    </script>

    <!-- import the webpage's javascript files -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
    <script src="https://unpkg.com/@tensorflow-models/speech-commands"></script>
    <script src="https://aframe.io/releases/1.2.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/donmccurdy/aframe-extras@v6.1.1/dist/aframe-extras.min.js"></script>


    <script type="text/javascript">
        let recognizer;
        let words;
        const wordList = ["zero", "one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "yes", "no", "up", "down", "left", "right", "stop", "go"];
        let modelLoaded = false;

        document.addEventListener('DOMContentLoaded', () => {
            const wrapperElement = document.getElementById('sp-cmd-wrapper');


            document.getElementById("audio-switch").addEventListener('change', (event) => {
                if (event.target.checked) {
                    if (modelLoaded) {
                        startListening();
                    } else {
                        loadModel();
                    }
                } else {
                    stopListening();
                }
            });
        });

        async function loadModel() {
            // Show the loading element
            const loadingElement = document.getElementById('demo-loading');
            loadingElement.classList.remove('hidden');

            // When calling `create()`, you must provide the type of the audio input.
            // - BROWSER_FFT uses the browser's native Fourier transform.
            recognizer = speechCommands.create("BROWSER_FFT");
            await recognizer.ensureModelLoaded()

            words = recognizer.wordLabels();
            modelLoaded = true;

            // Hide the loading element
            loadingElement.classList.add('hidden');
            startListening();
        }

        function startListening() {
            recognizer.listen(({ scores }) => {

                // Everytime the model evaluates a result it will return the scores array
                // Based on this data we will build a new array with each word and it's corresponding score
                console.log('scores :>> ', scores);
                scores = Array.from(scores).map((s, i) => ({ score: s, word: words[i] }));
                console.log('scores :>> ', scores);
                // After that we sort the array by scode descending
                scores.sort((s1, s2) => s2.score - s1.score);

                // And we highlight the word with the highest score
                let word = scores[0].word
                if (scores[0].score < 0.999) return;
                switch (word) {
                    case 'go':
                        document.getElementById('demo-loading').setAttribute("animation-mixer", "clip", "Walking")
                        break;
                    case 'up':
                        document.getElementById('demo-loading').setAttribute("animation-mixer", "clip", "Jump")
                        break;

                    default:
                    document.getElementById('demo-loading').setAttribute("animation-mixer", "clip", "Death")

                        break;
                }
                setTimeout(() => {
                    document.getElementById('demo-loading').setAttribute("animation-mixer", "clip", "Idle")
                }, 5000)
            },
                {
                    probabilityThreshold: 0.70
                });
        }

        function stopListening() {
            recognizer.stopListening();
        }
    </script>
</head>

<body>

    <a-scene stats>
        <!-- Environment for 2D and VR viewing. It's auto-hidden in AR mode. -->
        <a-entity environment="preset: forest; lighting: none; shadow: none; lightPosition: 0 2.15 0" hide-in-ar-mode>
        </a-entity>

        </a-entity>
        <a-camera position="0 5 5"></a-camera>
        <a-assets>
            <a-asset-item id="chair" src="./scene.gltf"></a-asset-item>
        </a-assets>
        <a-entity id="chair_">
            <a-entity id="demo-loading" animation-mixer="clip: Idle;" gltf-model="#chair"></a-entity>
        </a-entity>
    </a-scene>

    <div id="text">
        <label class="form-switch">
            <input type="checkbox" id="audio-switch">
            Microphone
        </label>
        <div id="demo-loading" class="hidden">Loading...</div>
    </div>
</body>

</html>